# 散列表（哈希表）
# 一、简介
## 1. 定义
&#8195; 散列表，又称哈希表，是一种存储记录的连续内存，通过哈希函数的应用，可以快速存储与查找数据。基本上，所谓的哈希法（Hashing）就是将本身的键值，通过特定的数学函数运算或者其他的方法，转换成相对于的数据存储地址，如下图所示。

![1.png](https://upload-images.jianshu.io/upload_images/16911112-c8a5c7cccf69198f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 举个例子：假如我们有 89 名选手参加学校运动会。为了方便记录成绩，每个选手胸前都会贴上自己的参赛号码。这 89 名选手的编号依次是 1 到 89，同时还要加上年级、班级这些更详细的信息，所以我们把编号的规则用 6 位数字来表示。比如 051167，其中，前两位 05 表示年级，中间两位 11 表示班级，最后两位还是原来的编号 1 到 89。这个时候我们该如何存储选手信息，才能够支持通过编号来快速查找选手信息呢？

&#8195; 我们可以截取参赛编号的后两位作为数组下标，来存取选手信息数据。当通过参赛编号查询选手信息的时候，我们用同样的方法，取参赛编号的后两位，作为数组下标，来读取数组中的数据，如下图所示。

![](https://upload-images.jianshu.io/upload_images/16911112-397d76bb10b8e9bf.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 这就是典型的散列思想。其中，参赛选手的编号我们叫做**键**（key）或者**关键字**。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫作**散列函数**（或“Hash 函数”“哈希函数”），而散列函数计算得到的值就叫作**散列值**（或“Hash 值”“哈希值”）。

## 2. 定义
&#8195; 我们可以总结出这样的规律：散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。

### 2.1 相关名词
* **bucket（桶**）：哈希表中存储数据的位置，每一个位置对应到唯一一个地址（bucked address）。桶就好比一个记录。

* **slot（槽**）：每一个记录可能包含好几个字段，而 slot 值的就是“桶”中的字段。

* **collision（碰撞**）：两项不同的数据，经过哈希函数计算后，对应到相同的地址。

* **溢出**：如果数据经过哈希函数计算后，所对应得到的 bucket 已满，就会使得 bucket 溢出。

* **哈希表**：存储记录的连续内存。

* **同义词（Synonym**）：两个标识符 $I_1$ 和 $I_2$ 经过哈希函数运算后的得到的数值相同，即 $f(I_1) = f(I_2)$，就称 $I_1$ 和 $I_2$ 对于 $f$ 这个哈希函数是同义词。

* **加载密度（Loading Factor**）：指的是标识符使用数量除以哈希表内槽的总数。

* **完美哈希（Perfect Hashing**）：没有碰撞也没有溢出的哈希函数。


### 2.2 设计原则
&#8195; 通常在设计哈希函数时应该遵循以下几个原则：

* 降低碰撞和溢出的产生；

* 哈希函数不宜过于复杂，越容易计算越佳；

* 尽量把文字的键值转换成数字的键值，以利于哈希函数的运算；

* 所涉及的哈希函数计算得到的值，尽量能均匀的分布在每一桶中，不要太过于集中在某些桶内，这样就可以降低碰撞，并减少溢出的处理。

### 2.3 设计要求
&#8195; 散列函数设计的基本要求：
1. 散列函数计算得到的散列值是一个非负整数；<br>
数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。

2. 如果 key1 = key2，那 hash(key1) == hash(key2)；<br>
相同的 key，经过散列函数得到的散列值也应该是相同的。

3. 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。<br>
这个要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。而且，因为数组的存储空间有限，也会加大散列冲突的概率。

### 2.4 散列冲突
&#8195; 再好的散列函数也无法避免散列冲突，我们常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。

1. **开放寻址法**

&#8195; 开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。先讲一个比较简单的探测方法，**线性探测**（Linear Probing）。

* **线性探测**

当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。如下图所示，这里面黄色的色块表示空闲位置，橙色的色块表示已经存储了数据。

![](https://upload-images.jianshu.io/upload_images/16911112-ff75c0750f7f245c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 从图中可以看出，散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是我们就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。

&#8195; 在散列表中查找元素的过程有点儿类似插入过程。我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

![](https://upload-images.jianshu.io/upload_images/16911112-49c916e2ae1c196d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 散列表跟数组一样，不仅支持插入、查找操作，还支持删除操作。对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别。我们不能单纯地把要删除的元素设置为空，我们可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。

![](https://upload-images.jianshu.io/upload_images/16911112-c07de3dc14f77a7c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。

&#8195; 对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，**二次探测**（Quadratic probing）和**双重散列**（Double hashing）。

* **二次探测**

&#8195; 所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+$1^2$，hash(key)+$2^2$……

* **双重散列**

&#8195; 所谓双重散列，意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。

&#8195; 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。装载因子的计算公式是：

* 散列表的装载因子 = 填入表中的元素个数 / 散列表的长度

&#8195; 装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

2. **链表法**

&#8195; 链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。我们来看这个图，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

![](https://upload-images.jianshu.io/upload_images/16911112-07ee88a9baa39943.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。

&#8195; 实际上，这两个操作的时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。

---

# 二、散列表的设计
## 1. 意义
&#8195; 我们知道，散列表的查询效率并不能笼统地说成是 O(1)。它跟散列函数、装载因子、散列冲突等都有关系。如果散列函数设计得不好，或者装载因子过高，都可能导致散列冲突发生的概率升高，查询效率下降。

&#8195; 在极端情况下，有些恶意的攻击者，还有可能通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。

&#8195; 如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。更直接点说，如果之前运行 100 次查询只需要 0.1 秒，那现在就需要 1 万秒。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。这也就是散列表碰撞攻击的基本原理。

## 2. 如何设计散列函数
### 2.1 设计要求
* 持快速地查询、插入、删除操作；
* 内存占用合理，不能浪费过多的内存空间；
* 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。

### 2.2 设计思路
1. 设计一个合适的散列函数；
    * 首先，散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接地影响到散列表的性能。
    * 其次，散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。
    * 实际工作中，我们还需要综合考虑各种因素。这些因素有关键字的长度、特点、分布、还有散列表的大小等。

2. 定义装载因子阈值，并且设计动态扩容策略；
    * 当散列表的装载因子超过某个阈值时，就需要进行扩容。装载因子阈值需要选择得当。如果太大，会导致冲突过多；如果太小，会导致内存浪费严重。
    
    * 装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。
    
        * 针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。
        
        * 假设每次扩容我们都申请一个原来散列表大小两倍的空间。如果原来散列表的装载因子是 0.8，那经过扩容之后，新散列表的装载因子就下降为原来的一半，变成了 0.4。
        
        * 针对数组的扩容，数据搬移操作比较简单。但是，针对散列表的扩容，数据搬移操作要复杂很多。因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。
    
    * 如何避免低效的扩容？
    
        * 为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。
        
        * 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。


3. 选择合适的散列冲突解决方法
    * 开放寻址法
        * 可以有效地利用 CPU 缓存加快查询速度，序列化起来比较简单；
        
        * 在删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据；冲突的代价更高。
        
        * **当数据量比较小、装载因子小的时候，适合采用开放寻址法**。
    
    * 链表法
        * 首先，链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好；
        
        * 链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。
        
        * **基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表**。
    
### 2.3 工业级散列表举例分析
1. 初始大小HashMap 

&#8195; 默认的初始大小是 16，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

2. 装载因子和动态扩容最大装载因子默认是 0.75，

&#8195; 当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。

3. 散列冲突解决方法HashMap 底层采用链表法来解决冲突。

&#8195; 即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。于是，在 JDK1.8 版本中，为了对 HashMap 做进一步优化，我们引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。我们可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。

* 4. 散列函数

&#8195; 散列函数的设计并不复杂，追求的是简单高效、分布均匀。

### 2.4 总结

&#8195; 关于散列函数的设计，我们要尽可能让散列后的值随机且均匀分布，这样会尽可能地减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响散列表的性能。

&#8195; 关于散列冲突解决方法的选择，比了开放寻址法和链表法两种方法的优劣和适应的场景。大部分情况下，链表法更加普适。而且，我们还可以通过将链表法中的链表改造成其他动态查找数据结构，比如红黑树，来避免散列表时间复杂度退化成 O(n)，抵御散列碰撞攻击。但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法。

&#8195; 对于动态散列表来说，不管我们如何设计散列函数，选择什么样的散列冲突解决方法。随着数据的不断增加，散列表总会出现装载因子过高的情况。这个时候，我们就需要启动动态扩容。

---

# 三、散列表和链表
&#8195; 回顾前面所学的数据结构，有两种数据结构，散列表和链表，经常会被放在一起使用。

&#8195; 在学链表的时候，讲到如何用链表来实现 LRU 缓存淘汰算法，但是链表实现的 LRU 缓存淘汰算法的时间复杂度是 O(n)，我们可以通过散列表可以将这个时间复杂度降低到 O(1)。

&#8195; 在学跳表的时候，提到 Redis 的有序集合是使用跳表来实现的，跳表可以看作一种改进版的链表。当时也提到，Redis 有序集合不仅使用了跳表，还用到了散列表。

## 1. LRU 缓存淘汰算法
### 1.1 缓存介绍
&#8195; 我们需要维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，我们就直接将链表头部的结点删除。

&#8195; 当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，我们就把它移动到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 O(n)。

&#8195; 总结一下，一个缓存（cache）系统主要包含下面这几个操作：
* 往缓存中添加一个数据；
* 从缓存中删除一个数据；
* 在缓存中查找一个数据。

&#8195; 这三个操作都要涉及“查找”操作，如果单纯地采用链表的话，时间复杂度只能是 O(n)。如果我们将散列表和链表两种数据结构组合使用，可以将这三个操作的时间复杂度都降低到 O(1)。具体的结构就是下面这个样子：

![](https://upload-images.jianshu.io/upload_images/16911112-1bf575199da97e0c.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 我们使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 hnext。

&#8195; 因为我们的散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是刚刚我们提到的**双向链表**，另一个链是散列表中的**拉链**。**前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。**

### 1.2 操作实现
1. 首先，我们来看如何**查找一个数据**。

    * 我们前面讲过，散列表中查找数据的时间复杂度接近 O(1)，所以通过散列表，我们可以很快地在缓存中找到一个数据。当找到数据之后，我们还需要将它移动到双向链表的尾部。

2. 其次，我们来看如何**删除一个数据**。

    * 我们需要找到数据所在的结点，然后将结点删除。借助散列表，我们可以在 O(1) 时间复杂度里找到要删除的结点。因为我们的链表是双向链表，双向链表可以通过前驱指针 O(1) 时间复杂度获取前驱结点，所以在双向链表中，删除结点只需要 O(1) 的时间复杂度。

3. 最后，我们来看如何**添加一个数据**。
    * 我们需要先看这个数据是否已经在缓存中；
    
    * 如果已经在其中，需要将其移动到双向链表的尾部；
    
    * 如果不在其中，还要看缓存有没有满。
    
        * 如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；
        
        * 如果没有满，就直接将数据放到链表的尾部。

&#8195; 这整个过程涉及的查找操作都可以通过散列表来完成。其他的操作，比如删除头结点、链表尾部插入数据等，都可以在 O(1) 的时间复杂度内完成。所以，这三个操作的时间复杂度都是 O(1)。至此，我们就通过散列表和双向链表的组合使用，实现了一个高效的、支持 LRU 缓存淘汰算法的缓存系统原型。

## 2. Redis 有序集合
&#8195; 实际上，在有序集合中，每个成员对象有两个重要的属性，key（键值）和 score（分值）。我们不仅会通过 score 来查找数据，还会通过 key 来查找数据。

&#8195; 举个例子，比如用户积分排行榜有这样一个功能：我们可以通过用户的 ID 来查找积分信息，也可以通过积分区间来查找用户 ID 或者姓名信息。这里包含 ID、姓名和积分的用户信息，就是成员对象，用户 ID 就是 key，积分就是 score。

&#8195; 所以，如果我们细化一下 Redis 有序集合的操作，那就是下面这样：
* 添加一个成员对象；

* 按照键值来删除一个成员对象；

* 按照键值来查找一个成员对象；

* 按照分值区间查找数据，比如查找积分在[100, 356]之间的成员对象；

* 按照分值从小到大排序成员变量；

&#8195; 如果我们仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢，解决方法与 LRU 缓存淘汰算法的解决方法类似。我们可以再按照键值构建一个散列表，这样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)。同时，借助跳表结构，其他操作也非常高效。

&#8195; 实际上，Redis 有序集合的操作还有另外一类，也就是查找成员对象的排名（Rank）或者根据排名区间查找成员对象，这个功能单纯用刚刚讲的这种组合结构就无法高效实现了。

## 3. 总结
&#8195; 散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历。

&#8195; 因为散列表是动态数据结构，不停地有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低。为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。

---

# 四、哈希算法
## 1. 介绍
&#8195; 将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

&#8195; 但是，要想设计一个优秀的哈希算法并不容易，需要满足的几点要求：
* 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；

* 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；

* 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；

* 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

## 2. 应用
&#8195; 哈希算法的应用非常非常多，我选了最常见的七个，分别是**安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储**。

### 2.1 应用一：安全加密

&#8195; 安全加密说到哈希算法的应用，最先想到的应该就是安全加密。最常用于加密的哈希算法是 MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和 SHA（Secure Hash Algorithm，安全散列算法）。除了这两个之外，当然还有很多其他加密算法，比如 DES（Data Encryption Standard，数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。

&#8195; 对加密算法来说，有两点格外重要：
* 第一点是很难**根据哈希值反向推导出原始数**据；
    * 加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数据，这是一个最基本的要求。

* 第二点是**散列冲突的概率要很小**；
    * 这里就基于组合数学中一个非常基础的理论，鸽巢原理（也叫抽屉原理）。这个原理本身很简单，它是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。
    * 我们知道，哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。这里你应该能想到，一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

### 2.2 应用二：唯一标识

&#8195; 举一个例子：如果要在海量的图库中，搜索一张图是否存在，我们不能单纯地用图片的元信息（比如图片名称）来比对，因为有可能存在名称相同但图片内容不同，或者名称不同图片内容相同的情况。

&#8195; 我们可以给每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识

&#8195; 如果还想继续提高效率，我们可以把每个图片的唯一标识，和相应的图片文件在图库中的路径信息，都存储在散列表中。当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。
* 如果不存在，那就说明这个图片不在图库中；

* 如果存在，我们再通过散列表中存储的文件路径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。

    * 如果一样，就说明已经存在；
    
    * 如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同的图片。


### 2.3 应用三：数据校验

&#8195; 我们知道，网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者下载过程中出现了错误，所以下载的文件块可能不是完整的。如果我们没有能力检测这种恶意修改或者文件下载出错，就会导致最终合并后的电影无法观看，甚至导致电脑中毒。

&#8195; 我们通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

### 2.4 应用四：散列函数

&#8195; 散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。不过，相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。

&#8195; 不仅如此，散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，**散列函数用的散列算法一般都比较简单，比较追求效率**。

### 2.5 应用五：负载均衡

&#8195; 我们知道，负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

&#8195; 最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。

&#8195; 这种方法简单直观，但也有几个弊端：如果客户端很多，映射表可能会很大，比较浪费内存空间；客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；如果借助哈希算法，这些问题都可以非常完美地解决。

&#8195; **我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号**。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

### 2.6 应用六：数据分片

&#8195; 哈希算法还可以用于数据的分片。

1. **如何统计“搜索关键词”出现的次数？**

&#8195; 假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

&#8195; **我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度**。具体的思路是这样的：为了提高处理的速度，我们用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

&#8195; 这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

2. **如何快速判断图片是否在图库中？**

&#8195; 假设现在我们的图库中有 1 亿张图片，很显然，在单台机器上构建散列表是行不通的。因为单台机器的内存有限，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限。

&#8195; 我们同样可以对数据进行分片，然后采用多机处理。我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。

&#8195; 当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。

&#8195; 现在，我们来估算一下，给这 1 亿张图片构建散列表大约需要多少台机器。散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节。文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节。

&#8195; 如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。

&#8195; 所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。

&#8195; 实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。

### 2.7 应用七：分布式存储

&#8195; 现在互联网面对的都是海量的数据、海量的用户。我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。

&#8195; 我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。因为，这里并不是简单地加个机器就可以了。

&#8195; 举个例子：原来的数据是通过与 10 来取模的，比如 13 这个数据，存储在编号为 3 这台机器上。但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。

![](https://upload-images.jianshu.io/upload_images/16911112-c38650b19c5355e7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195; 因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生[*雪崩效应*](https://zh.wikipedia.org/wiki/%E9%9B%AA%E5%B4%A9%E6%95%88%E5%BA%94)，压垮数据库。

&#8195; 所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，**一致性哈希算法**就要登场了。假设我们有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。

&#8195; 当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。


## 3. 总结

1. 第一个应用是唯一标识，哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来表示很大的数据。

2. 第二个应用是用于校验数据的完整性和正确性。

3. 第三个应用是安全加密，任何哈希算法都会出现散列冲突，但是这个冲突概率非常小。越是复杂哈希算法越难破解，但同样计算时间也就越长。所以，选择哈希算法的时候，要权衡安全性和计算时间来决定用哪种哈希算法。

4. 第四个应用是散列函数，它对哈希算法的要求非常特别，更加看重的是散列的平均性和哈希算法的执行效率。

5. 第五个应用是负载均衡，在负载均衡应用中，利用哈希算法替代映射表，可以实现一个会话粘滞的负载均衡策略。

6. 第六个应用是数据分片，在数据分片应用中，通过哈希算法对处理的海量数据进行分片，多机分布式处理，可以突破单机资源的限制。

7. 第七个是分布式，在分布式存储应用中，利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题。
