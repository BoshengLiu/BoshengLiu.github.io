# 数据探索
# 一、数据质量分析
## 1. 缺失值分析
数据的缺失主要包含记录的缺失和记录中某个字段信息的缺失，两者都会造成分析结果的不准确。

### 1.1 造成数据缺失的原因
* 信息暂时无法获取，或者信息的获取代价太大；
* 信息被遗漏；
* 属性值不存在。

### 1.2 缺失值的影响
* 数据挖掘建模将丢失大量信息；
* 数据挖掘模型所表现出的不稳定性更加显著，系统中蕴涵的确定性成分更难把握；
* 包含空值的数据会是建模陷入混乱，导致输出不可靠。

### 1.3 缺失值分析
* 使用简单的统计分析，可以得到含有缺失值的属性个数，以及每个属性的未缺失数、缺失数和缺失率。

## 2. 异常值分析
异常值指样本中的个别值，其数值明显偏离其余的观测值，也称为离群点。对于异常值分析有以下几种方法：

### 2.1 简单统计量分析
* 可以先对变量做一个描述性统计，进而查看那些数据是不合理的，最常用的统计量为最大值和最小值。

### 2.2 3σ原则
* 如果数据服从正态分布，在3标准差原则下，异常值被定义为一组测定值中与平均值的偏差超过3倍标准差的值。在正态分布的假设下，距离平均值$P(|x-μ|>3σ)≤0.003$属于极小概率事件。如果数据不服从正态分布，也可以用远离平均值的多少倍标准差来描述。

### 2.3 箱型图分析
* 箱型图提供了识别异常值的一个标准，异常值通常被定义为：
$$Outliers \geq Q_U＋1.5IQR \quad 或 \quad Outliers \leq Q_L－1.5IQR
$$其中，$Outliers$是异常值；$Q_L$称为下四分位数，表示全部观察值中有四分之一的数据取值比它小；
$Q_U$称为上四分位数，表示全部观察值中有四分之一的数据取值比它大；
IQR称为四分位数间距，是上四分位数$Q_U$与下四分位数$Q_L$之差，其间包含了全部观察值的一半。

* 程序参考如下：
```python
Q_up = np.percentile(df[col], 25)
Q_low = np.percentile(df[col], 75)
IQR = Q_up - Q_low
outlier_step = 1.5 * IQR
df = df[(df[col].values > Q_low - outlier_step) | (df[col] < Q_up + outlier_step)]
```

&#8195;  箱型图依据实际数据绘制，没有对数据作任何限制性要求（如服从某种特定的分布形式），它只是真实直观地表现数据分布的本来面貌；另一方面，箱型图判断异常值的标准以四分位数和四分位距为基础，四分位数具有一定的鲁棒性：多达25%的数据可以变得任意远而不会很大地扰动四分位数，所以异常值不能对这个标准施加影响。由此可见，箱型图识别异常值的结果比较客观，在识别异常值方面有一定的优越性，如图所示。

![](https://upload-images.jianshu.io/upload_images/16911112-b9bf9b3ba70170ec.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 3. 一致性分析

* 数据不一致性式子数据的矛盾性、不相容性。
在实际数据挖掘过程中，不一致性数据可能是由于被挖掘的数据来源于不同的数据源、对于重复存放的数据未能进行一致性更新造成的。

---

# 二、数据特征分析
## 1. 分布分析

&#8195;  分布分析能解释数据的分布特征和分布类型。对于定量数据，可通过绘制频率分布表、直方图、茎叶图进行直观非常；对于定性分类数据，可以饼图和条形图显示分布情况。

### 1.1 定量数据的分布分析
* 步骤：
  * 1. 求极差；
  * 2. 决定组距和组数；
  * 3. 决定分点；
  * 4. 列出频率分布表；
  * 5. 绘制频率直方图。

* 遵循的原则：
  * 1. 各组之间必须是相互排斥的； 
  * 2. 各组必须要将所有的数据包含在内；
  * 3. 各组的组宽最好相等。

### 1.2 定性数据的分布分析
* 对于定性变量，常常根据变量的分类类型来分组，可以采用饼图和条形图来描述定性变量的分布。

### 1.3 表示分布形状的统计
**1. 分布形状**

&#8195;  分布形状使用偏度系数和峰度系数来度量，偏度是用于衡量数据分布对称性的统计量：通过对偏度系数的测量，我们能够判定数据分布的不对称程度以及方向。
* 对于正态分布(或严格对称分布)偏度等于0；
* 若偏度为负， 则x均值左侧的离散度比右侧强；
* 若偏度为正， 则x均值左侧的离散度比右侧弱。

参考图片如下：

![](https://upload-images.jianshu.io/upload_images/16911112-0a20e840383ef96c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**2. 峰度**

&#8195;  峰度是用于衡量数据分布陡峭或平滑的统计量，通过对峰度系数的测量，我们能够判定数据分布相对于正态分布而言是更陡峭还是平缓。

* 正态分布的峰度为3，
* 当时间序列的曲线峰值比正态分布的高时，峰度大于3；
* 当比正态分布的低时，峰度小于3。

**3. 偏度系数**

&#8195;  偏度系数反映数据分布偏移中心位置的程度，记为$S_K$，则有 $S_K$= (均值一中位数)/标准差。偏度系数是描述分布偏离对称性程度的一个特征数。

&#8195;  正态分布的偏度为0，偏度<0称分布具有负偏离（左偏态），此时数据位于均值左边的位于右边的多，有个尾巴拖到左边，说明左边有极端值，偏度>0称分布具有正偏离（右偏态）。偏度接近如于0 ，可认为分布对称。例如：知道分布有可能在偏度上偏离正态分布，则可用偏度来检验分布的正态性。偏度的绝对值数值越大表示其分布形态的偏斜程度越大。

**4. 峰度系数**

&#8195;  峰度系数（Kurtosis）用来度量数据在中心聚集程度，记为K，描述总体中所有取值分布形态陡缓程度的统计量(与正态分布比较,，就是正态分布的峰顶)。

&#8195;  例如：正态分布的峰度系数值是3，K>3的峰度系数说明观察量更集中，有比正态分布更短的尾部；K<3的峰度系数说明观测量不那么集中，有比正态分布更长的尾部。

峰度系数公式是：
$$K = \frac{\sum_{i=1}^{k} (x_i-x)^4 f_i}{ns^4}$$

## 2. 对比分析
&#8195;  对比分析时将两个相互联系的指标进行比较，从数量上展示和说明研究对象规模的大小、水平的高低，速度的亏阿曼，以及各种关系是否协调。特别适用于指标间的纵横向比较、时间序列的比较分析。对比分析主要有**绝对数对比**和**相对数对比**。

### 2.1 绝对数对比
* 绝对数相比时利用绝对数进行对比，从而能寻找差异的一致方法。

### 2.2 相对数对比
* 结构相对数：将同一总体内的部分数值与全部数值独臂求得比重，泳衣说明事物的性质、结构或重量。
* 比例相对数：将同一总体内的不同部分数值进行对比，表明总以内各部分的比例关系。
* 比较相对数：将同一时期两个性质相同的指标数值进行对比，说明同类现象在不同空间条件下的数量对比关系。
* 强度相对数：将两个性质不同但有一定联系的总量指标进行对比，用以说明现象的强度、密度和普遍程度。
* 计划完成度相对数：用某一时期完成数与计划数对比，用以说明计划完成度。
* 动态相对数：将同一现象在不同时期的指标进行对比，用以说明发展方向和变化速度。

## 3. 统计量分析
 用统计指标对定量数据进行统计描述，常从集中趋势和离中趋势两个方面进行分析。

### 3.1 集中趋势
* **均值**：均值（mean）又称算数平均数，描述数据去指导额平均位置，数学表达式：

$$ \bar x =  \sum_{i=1}^n x_i$$

* **中位数**：对于倾斜（非对称）的数据，能够更好地描述数据中心的统计量是中位数（median），中位数是有序数据值的中间值，中位数可避免极端数据，代表这数据总体的中等情况。例如：从小到大排序，总数是奇数，取中间的数，总数是偶数，取中间两个数的平均数。

* **众数**：众数（mode）是变量中出现频率最大的值，通常用于对定性数据确定众数，例如：用户状态（正常，欠费停机，申请停机，拆机、消号），该变量的众数是“正常”，这种情况是正常的。

### 3.2 离中趋势
* **极差**：极差为最大值和最小值之差。极差对数值的极端非常敏感，并且忽略了最大值与最小值之间的数据分布情况。

* **标准差**：标准差用于度量数据分布的离散程度，低标准差意味着数据观测趋向于靠近均值，高标准差表示数据散步在一个大的值域中。计算公式：
$$s = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \bar x)^2}{n}}, \quad 其中 \bar x 为均值$$

* **变异系数**：变异系数主要用来比较两个或多个具有不同单位或不同波动幅度的数据集的离中趋势。计算公式如下：
$$CV = \frac{s}{v} \times 100\% $$

* **四分位数间距**：四分位数包含上分位数和下分位数。将所有数值按照从小到大排列分成四等份，第一个分割点为下四分位数，第三个分割点为上四分位点。四分位间距为，上四分位数$Q_U$与下四分位数$Q_L$之差，公式为：
$$IQR = Q_U - Q_L $$

## 4. 周期性分析
&#8195;  周期性分析是探索某个变量是否随着时间变化而呈现出某种周期性变化的趋势，时间尺度的选择有年度、季度、月份、周度、天和小时等时间周期。

&#8195;  在进行周期性分析时，不能简单地以天或月来对数据进行分析，因为，在大多数情况下，人们都是在周一到周五工作，在周六和周日休息，所以，应该根据用户的行为习惯和业务场景，选择合适的时间尺度。结合笔者的工作经验，最常用的周期是周。

&#8195;  对于消费行业数据，节假日是一个必须要考虑的时间点，比如，法定节假日、双11、618等，还有周末，对于这样的时间点，数据量会增加很多，没有节假日和有节假日，数据的差距是非常大的。

&#8195;  对于某些数据，这些特殊的时间点不一定带来数据的暴增，例如，对于一些技术类网站，由于人们只在工作日访问，因此访问量在工作日明显增大，而在周末、或节假日则会明显降低。对于这些特殊的时间点，在分析数据时，应考虑周全，特殊处理。

## 5. 贡献度分析
&#8195;  贡献度分析又叫做帕累托分析，帕累托分析依据的原理是20/80定律，80%的效益常常来自于20%的投入，而其他80%的投入却只产生了20%的效益，这说明，同样的投入在不同的地方会产生不同的效益。帕累托图的绘制过程是按照贡献度从高到低依次排列，并绘制累积贡献度曲线。当样本数量足够大时，贡献度通常会呈现20/80分布。

* 帕累托图如下：

![](https://upload-images.jianshu.io/upload_images/16911112-3edeeea815c5cd98.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 6. 相关性分析
&#8195;  相关分析（Analysis of Correlation）是网站分析中经常使用的分析方法之一。通过对不同特征或数据间的关系进行分析，发现业务运营中的关键影响及驱动因素。并对业务的发展进行预测。

&#8195;  相关分析的方法很多，初级的方法可以快速发现数据之间的关系，如正相关，负相关或不相关。中级的方法可以对数据间关系的强弱进行度量，如完全相关，不完全相关等。高级的方法可以将数据间的关系转化为模型，并通过模型对未来的业务发展进行预测。下面我们以一组广告的成本数据和曝光量数据对每一种相关分析方法进行介绍。

&#8195;  以下是每日广告曝光量和费用成本的数据，每一行代表一天中的花费和获得的广告曝光数量。凭经验判断，这两组数据间应该存在联系，但仅通过这两组数据我们无法证明这种关系真实存在，也无法对这种关系的强度进行度量。因此我们希望通过相关分析来找出这两组数据之间的关系，并对这种关系进度度量。

![](https://upload-images.jianshu.io/upload_images/16911112-2848ef0e2edefdc2.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 6.1 图表相关分析（折线图及散点图）
&#8195;  第一种相关分析方法是将数据进行可视化处理，简单的说就是绘制图表。单纯从数据的角度很难发现其中的趋势和联系，而将数据点绘制成图表后趋势和联系就会变的清晰起来。对于有明显时间维度的数据，我们选择使用折线图。

&#8195;  为了更清晰的对比这两组数据的变化和趋势，我们使用双坐标轴折线图，其中主坐标轴用来绘制广告曝光量数据，次坐标轴用来绘制费用成本的数据。通过折线图可以发现，费用成本和广告曝光量两组数据的变化和趋势大致相同，从整体的大趋势来看，费用成本和广告曝光量两组数据都呈现增长趋势。从规律性来看费用成本和广告曝光量数据每次的最低点都出现在同一天。从细节来看，两组数据的短期趋势的变化也基本一致。

![](https://upload-images.jianshu.io/upload_images/16911112-103fd7a4807831b7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195;  经过以上这些对比，我们可以说广告曝光量和费用成本之间有一些相关关系，但这种方法在整个分析过程和解释上过于复杂，如果换成复杂一点的数据或者相关度较低的数据就会出现很多问题。

&#8195;  比折线图更直观的是散点图。散点图去除了时间维度的影响，只关注广告曝光量和费用成本这里两组数据间的关系。在绘制散点图之前，我们将费用成本标识为X，也就是自变量，将广告曝光量标识为y，也就是因变量。下面是一张根据每一天中广告曝光量和费用成本数据绘制的散点图，X轴是自变量费用成本数据，Y轴是因变量广告曝光量数据。从数据点的分布情况可以发现，自变量x和因变量y有着相同的变化趋势，当费用成本的增加后，广告曝光量也随之增加。

![](https://upload-images.jianshu.io/upload_images/16911112-471a97ff7a70eb83.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

&#8195;  折线图和散点图都清晰的表示了广告曝光量和费用成本两组数据间的相关关系，优点是对相关关系的展现清晰，缺点是无法对相关关系进行准确的度量，缺乏说服力。并且当数据超过两组时也无法完成各组数据间的相关分析。若要通过具体数字来度量两组或两组以上数据间的相关关系，需要使用第二种方法：协方差。

### 6.2 协方差及协方差矩阵
&#8195;  第二种相关分析方法是计算协方差。协方差用来衡量两个变量的总体误差，如果两个变量的变化趋势一致，协方差就是正值，说明两个变量正相关。如果两个变量的变化趋势相反，协方差就是负值，说明两个变量负相关。如果两个变量相互独立，那么协方差就是0，说明两个变量不相关。以下是协方差的计算公式：
$$Cov(X,Y) = \frac{ \sum_{i=1}^{n} (X_i - \bar X)(Y_i - \bar Y ) }
{n-1} $$

协方差只能对两组数据进行相关性分析，当有两组以上数据时就需要使用协方差矩阵。下面是三组数据x，y，z，的协方差矩阵计算公式。
$$Cov(X,Y,Z) = 
\begin{pmatrix}
cov(x,x) & cov(x,y) & cov(x,z)\\ 
cov(y,x) & cov(y,y) & cov(y,z)\\ 
cov(z,x) & cov(z,y) & cov(z,z)\\ 
\end{pmatrix}
$$

&#8195;  协方差通过数字衡量变量间的相关性，正值表示正相关，负值表示负相关。但无法对相关的密切程度进行度量。当我们面对多个变量时，无法通过协方差来说明那两组数据的相关性最高。要衡量和对比相关性的密切程度，就需要使用下一个方法：相关系数

### 6.3 相关系数
&#8195;  第三个相关分析方法是相关系数。相关系数(Correlation coefficient)是反应变量之间关系密切程度的统计指标，相关系数的取值区间在1到-1之间。1表示两个变量完全线性相关，-1表示两个变量完全负相关，0表示两个变量不相关。数据越趋近于0表示相关关系越弱。

* **Pearson相关系数**

&#8195;  一般用于分析两个连续型变量之间的关系，其计算公式如下：
$$
r = \frac{\sum_{i=1}^{n}(x_i-\bar x)(x_i-\bar x)(y_i-\bar y)}
{\sqrt{\sum_{i=1}^{n}(x_i-\bar x)^2 \sum_{i=1}^{n}(y_i-\bar y)^2}}
$$

&#8195;  相关系数r的取值范围：$-1\leq r \leq 1 $，其中$0<|r|<1$表示存在不同线性相关：

$$\begin{cases}
|r|\leq 0.3,  & \text{不存在线性相关} \\
0.3<|r|\leq 0.5, & \text{低度线性相关} \\
0.5<|r|\leq 0.8,  & \text{显著线性相关} \\
|r|>0.8, & \text{高度线性相关} \\
\end{cases}$$

* **Spearman秩相关系数**

&#8195;  Pearman线性相关系数要求连续变量的取值服从正态分布。不服从正态分布的变量类或等级变量之间的关联性可采用性Spearman相关系数，也称等级相关系数，其计算公式如下：
$$r = 1 - \frac{6\sum_{i=1}^{n}(R_i-Q_i)^2}{n(n^2-1)}$$

&#8195;  对两个变量承兑的取值分布安装从小到大（或者从大到小）顺序编秩，$R_i$代表$x_i$的秩，$Q_i代表y_i$的秩次，$R_i-Q_i$表示秩次之差。

* **判定系数**

&#8195;  判定系数是相关系数的平方，用$r^2$表示。用来衡量回归方程对y的解释程度。判定系数的取值范围：$0\leq r^2 \leq 1$。$r^2$越接近1，表示x与y之间的相关性越强；$r^2$越接近0，表示两个变量之间几乎没有直线相关关系。
$$ r = 1 - \frac{6\sum_{i=1}^{n}(R_i-Q_i)^2}{n(n^2-1)} $$